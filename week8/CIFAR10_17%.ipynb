{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import một số thư viện cần thiết.\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "# Sử dụng một mẹo nhỏ để vẽ hình trên cùng một dòng thay vì mở cửa sổ mới\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # đặt kích thước mặc định cho hình\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Một mẹo nhỏ để notebook tự load lại các module bên ngoài;\n",
    "# xem thêm tại http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "pca_retain = 800\n",
      "hid_layer_sizes = [4000, 1000, 4000]\n",
      "batchsize = 100\n",
      "zae_threshold = 1.0\n",
      "momentum = 0.9\n",
      "pretrain, zae:       lr = 0.001000, epc = 800\n",
      "pretrain, lin:       lr = 0.000100, epc = 800, wd = 1.000\n",
      "logistic regression: lr = 0.500000, epc = 1000\n",
      "finetune:            lr = 0.005000, epc = 1000\n"
     ]
    }
   ],
   "source": [
    "# Set super parameters \n",
    "\n",
    "pca_retain = 800\n",
    "batchsize = 100\n",
    "zae_threshold = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... pre-processing\n",
      "Centralizing data...  Done.\n",
      "Computing covariance...  Done.\n",
      "Eigen-decomposition... Done. Maximum stable PCs: 3072\n",
      "Number of selected PCs: 800, ratio of retained variance: 0.989758\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Reshape\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "# Add Neurobricks Package path\n",
    "import sys\n",
    "sys.path.append(r'/home/lntk/Desktop/cifar10/NeuroBricks/neurobricks')\n",
    "\n",
    "# Preprocessing\n",
    "from preprocess import SubtractMeanAndNormalizeH, PCA\n",
    "import theano\n",
    "\n",
    "print \"\\n... pre-processing\"\n",
    "preprocess_model = SubtractMeanAndNormalizeH(X_train.shape[1])\n",
    "map_fun = theano.function([preprocess_model.varin], preprocess_model.output())\n",
    "\n",
    "pca_obj = PCA()\n",
    "pca_obj.fit(map_fun(X_train), retain=pca_retain, whiten=True)\n",
    "preprocess_model = preprocess_model + pca_obj.forward_layer\n",
    "preprocess_function = theano.function([preprocess_model.varin], preprocess_model.output())\n",
    "\n",
    "pcamapping = theano.function([pca_obj.forward_layer.varin], pca_obj.forward_layer.output())\n",
    "pcaback = theano.function([pca_obj.backward_layer.varin], pca_obj.backward_layer.output())\n",
    "\n",
    "X_train = preprocess_function(X_train)\n",
    "X_test = preprocess_function(X_test)\n",
    "\n",
    "print \"Done.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training data shape: ', (50000, 800))\n",
      "('Training labels shape: ', (50000, 1))\n",
      "('Test data shape: ', (10000, 800))\n",
      "('Test labels shape: ', (10000, 1))\n"
     ]
    }
   ],
   "source": [
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change labels to one-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 2.3030 - acc: 0.0991\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.3020 - acc: 0.0958\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.3010 - acc: 0.1053\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 2.3001 - acc: 0.1059\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2992 - acc: 0.1100\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.2984 - acc: 0.1117\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.2975 - acc: 0.1117\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.2966 - acc: 0.1123\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.2958 - acc: 0.1122\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2949 - acc: 0.1160\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2941 - acc: 0.1164\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.2932 - acc: 0.1162\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 2.2923 - acc: 0.1202\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2913 - acc: 0.1222\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2902 - acc: 0.1210\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2891 - acc: 0.1248\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.2877 - acc: 0.1236\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.2860 - acc: 0.1301\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2840 - acc: 0.1338\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2816 - acc: 0.1376\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2791 - acc: 0.1357\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2766 - acc: 0.1388\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.2743 - acc: 0.1435\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2720 - acc: 0.1445\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2700 - acc: 0.1447\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2679 - acc: 0.1455\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2660 - acc: 0.1459\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2644 - acc: 0.1464\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2628 - acc: 0.1479\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2614 - acc: 0.1491\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2600 - acc: 0.1509\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2588 - acc: 0.1521\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2575 - acc: 0.1536\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2563 - acc: 0.1540\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2551 - acc: 0.1546\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2540 - acc: 0.1551\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2529 - acc: 0.1555\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2517 - acc: 0.1563\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 2.2508 - acc: 0.1566\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2496 - acc: 0.1577\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2487 - acc: 0.1580\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2477 - acc: 0.1587\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 2.2467 - acc: 0.1591\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2455 - acc: 0.1588\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2444 - acc: 0.1596\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2434 - acc: 0.1603\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2423 - acc: 0.1613\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 2.2411 - acc: 0.1611\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2400 - acc: 0.1612\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2389 - acc: 0.1614\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2379 - acc: 0.1622\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2367 - acc: 0.1625\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2354 - acc: 0.1627\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2343 - acc: 0.1629\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2331 - acc: 0.1632\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2317 - acc: 0.1642\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2305 - acc: 0.1651\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 79s 2ms/step - loss: 2.2291 - acc: 0.1655: 3s - loss: 2\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 85s 2ms/step - loss: 2.2279 - acc: 0.1655\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 86s 2ms/step - loss: 2.2264 - acc: 0.1659\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 2.2251 - acc: 0.1664\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2236 - acc: 0.1664\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2219 - acc: 0.1669\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2203 - acc: 0.1677\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2187 - acc: 0.1679\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2167 - acc: 0.1686\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.2149 - acc: 0.1694\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2130 - acc: 0.1692\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.2110 - acc: 0.1701\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 2.2091 - acc: 0.1708\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.2069 - acc: 0.1712\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2050 - acc: 0.1713\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.2026 - acc: 0.1722\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.2001 - acc: 0.1736\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.1979 - acc: 0.1740\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.1956 - acc: 0.1751\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.1933 - acc: 0.1763\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.1906 - acc: 0.1777\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.1881 - acc: 0.1783\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.1854 - acc: 0.1795\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.1831 - acc: 0.1799\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.1801 - acc: 0.1815\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.1779 - acc: 0.1819\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.1748 - acc: 0.1837\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.1718 - acc: 0.1847\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.1698 - acc: 0.1840\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.1663 - acc: 0.1861\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 2.1638 - acc: 0.1864\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.1612 - acc: 0.1871\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.1583 - acc: 0.1882\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 2.1552 - acc: 0.1882\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.1519 - acc: 0.1898\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.1491 - acc: 0.1908\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.1461 - acc: 0.1914\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 2.1432 - acc: 0.1923\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 2.1404 - acc: 0.1929\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.1368 - acc: 0.1945\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 2.1336 - acc: 0.1949\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.1302 - acc: 0.1964\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 2.1272 - acc: 0.1973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8581dea190>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4000, input_dim=800)) \n",
    "model.add(keras.layers.ThresholdedReLU(theta=zae_threshold))\n",
    "model.add(Dense(1000))\n",
    "model.add(Dense(4000))\n",
    "model.add(keras.layers.ThresholdedReLU(theta=zae_threshold))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=1e-4, decay=1e-6, momentum=0.95, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=100,\n",
    "          batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 339us/step\n",
      "[2.2171088075637817, 0.17220000095665455]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=100)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/lntk/Desktop/cifar10_1904_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
